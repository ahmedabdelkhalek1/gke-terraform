<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Technical Documentation - GKE Demo with Terraform</title>
<style>
  body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
  h1, h2, h3 { color: #2c3e50; }
  table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }
  th, td { border: 1px solid #ddd; padding: 8px; }
  th { background-color: #f2f2f2; text-align: left; }
  img { max-width: 100%; height: auto; margin: 10px 0; }
  pre { background-color: #f4f4f4; padding: 10px; overflow-x: auto; }
  code { font-family: monospace; }
</style>
</head>
<body>

<h1>Technical Documentation - GKE Demo with Terraform</h1>

<h2>1. Introduction</h2>
<p>This project contains Terraform configurations to deploy a Google Kubernetes Engine (GKE) cluster with custom networking settings.</p>

<h3>Prerequisites</h3>
<ul>
  <li>Google Cloud Platform (GCP) Account</li>
  <li>Google Cloud SDK installed</li>
  <li>Terraform installed</li>
  <li>GCP Project with required APIs enabled:
    <ul>
      <li>Compute Engine API</li>
      <li>Kubernetes Engine API</li>
      <li>Cloud Resource Manager API</li>
    </ul>
  </li>
</ul>

<h2>2. Architecture and Network Configuration</h2>
<p>The cluster is configured with the following IP ranges:</p>
<table>
  <thead>
    <tr><th>Component</th><th>IP Range</th></tr>
  </thead>
  <tbody>
    <tr><td>Nodes</td><td>10.0.0.0/16</td></tr>
    <tr><td>Pods</td><td>10.1.0.0/16</td></tr>
    <tr><td>Services</td><td>10.2.0.0/16</td></tr>
  </tbody>
</table>

<h3>Network Setup</h3>
<p>The project creates a custom VPC network and subnet with secondary IP ranges for pods and services. This enables VPC-native routing for the GKE cluster.</p>

<h3>Existing Network Screenshots</h3>
<p>Pods CIDR Range:</p>
<img src="./images/PodsCIDR.png" alt="Pods CIDR Range" />
<p>Services CIDR Range:</p>
<img src="./images/ServicesCIDR.png" alt="Services CIDR Range" />

<h3>Suggested Additional Screenshots</h3>
<ul>
  <li><strong>Terraform Plan Output:</strong> Screenshot of the terminal showing <code>terraform plan</code> output before applying changes. Place this in the Usage section before deployment steps.</li>
  <li><strong>GKE Cluster Dashboard:</strong> Screenshot of the GKE cluster overview page in the GCP Console. Place this in the Architecture section to visualize the cluster.</li>
  <li><strong>Kubectl Nodes and Pods:</strong> Screenshot of <code>kubectl get nodes</code> and <code>kubectl get pods --all-namespaces</code> outputs. Place this in the Usage section after deployment.</li>
  <li><strong>Network Topology Diagram:</strong> A simple diagram showing the VPC, subnet, and cluster networking. Place this in the Architecture section.</li>
</ul>

<h2>3. Terraform Modules and Resources</h2>
<h3>Main Module Overview</h3>
<p>The project uses a Terraform module located in <code>infra/modules/gke</code> to encapsulate the GKE cluster setup. The module provisions the cluster, node pools, and networking resources.</p>

<h3>Module Input Variables</h3>
<table>
  <thead>
    <tr><th>Name</th><th>Description</th><th>Type</th><th>Default</th><th>Required</th></tr>
  </thead>
  <tbody>
    <tr><td>project_id</td><td>GCP project id</td><td>string</td><td>n/a</td><td>Yes</td></tr>
    <tr><td>region</td><td>Region</td><td>string</td><td>us-east1</td><td>No</td></tr>
    <tr><td>node_locations</td><td>Availability zones of the GKE nodes</td><td>list(string)</td><td>n/a</td><td>Yes</td></tr>
    <tr><td>node_ip_range</td><td>IP address range of GKE nodes</td><td>string</td><td>10.0.0.0/16</td><td>No</td></tr>
    <tr><td>pod_ip_range</td><td>IP address range of Kubernetes pods</td><td>string</td><td>10.1.0.0/16</td><td>No</td></tr>
    <tr><td>service_ip_range</td><td>IP address range of Kubernetes services</td><td>string</td><td>10.2.0.0/16</td><td>No</td></tr>
    <tr><td>version_prefix</td><td>Kubernetes engine version prefix</td><td>string</td><td>n/a</td><td>No</td></tr>
    <tr><td>machine_type</td><td>Node instance category</td><td>string</td><td>n/a</td><td>No</td></tr>
    <tr><td>cluster_name</td><td>GKE cluster name</td><td>string</td><td>online-boutique-demo</td><td>No</td></tr>
  </tbody>
</table>

<h3>Module Outputs</h3>
<table>
  <thead>
    <tr><th>Name</th><th>Description</th></tr>
  </thead>
  <tbody>
    <tr><td>region</td><td>GCloud Region</td></tr>
    <tr><td>kubernetes_cluster_name</td><td>GKE Cluster Name</td></tr>
    <tr><td>kubernetes_cluster_host</td><td>GKE Cluster Host</td></tr>
    <tr><td>cluster_ca_certificate</td><td>Base64 encoded cluster CA certificate</td></tr>
    <tr><td>client_certificate</td><td>Base64 encoded client certificate</td></tr>
    <tr><td>client_key</td><td>Base64 encoded client key</td></tr>
  </tbody>
</table>

<h3>Node Pool Configuration</h3>
<p>The node pool is configured with the following settings:</p>
<ul>
  <li>3 nodes per zone</li>
  <li>Machine type specified by <code>machine_type</code> variable</li>
  <li>Disk size: 30GB standard persistent disk</li>
  <li>OAuth scopes for logging, monitoring, and storage read-only</li>
  <li>Node labels include the project ID as environment</li>
  <li>Metadata disables legacy endpoints for security</li>
</ul>

<h2>4. Usage and Deployment</h2>
<p>Follow these steps to deploy the GKE cluster:</p>
<ol>
  <li>Clone the repository:
    <pre><code>git clone https://github.com/cvitaa11/gke-demo.git
cd gke-demo/infra/example
</code></pre>
  </li>
  <li>Create a <code>terraform.tfvars</code> file with your project settings:
    <pre><code>project_id     = "your-project-id"
region         = "your-desired-region"
node_locations = ["your-desired-AZs"]
</code></pre>
  </li>
  <li>Initialize Terraform:
    <pre><code>terraform init
</code></pre>
  </li>
  <li>Review the plan:
    <pre><code>terraform plan
</code></pre>
    <p><em>Consider adding a screenshot of this output here.</em></p>
  </li>
  <li>Apply the configuration:
    <pre><code>terraform apply
</code></pre>
  </li>
  <li>Configure kubectl to access the cluster:
    <pre><code>gcloud container clusters get-credentials $(terraform output -raw kubernetes_cluster_name) --region $(terraform output -raw region)
</code></pre>
    <p><em>Consider adding a screenshot of <code>kubectl get nodes</code> output here.</em></p>
  </li>
</ol>

<h2>5. Cleanup and Notes</h2>
<p>To destroy the created resources, run:</p>
<pre><code>terraform destroy
</code></pre>
<p>Notes:</p>
<ul>
  <li>The configuration uses minimal resources to stay within GCP's free tier.</li>
  <li>The cluster is deployed in a single zone for cost optimization.</li>
  <li>Monitor your GCP usage and costs carefully.</li>
</ul>

<h2>6. Appendices</h2>
<p>You may add additional screenshots or diagrams here as needed.</p>

</body>
</html>
